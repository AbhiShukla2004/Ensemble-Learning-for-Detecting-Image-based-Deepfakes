Ensemble of Pre-trained Models for Deepfake Detection
This repository contains code and resources for detecting image-based deepfakes using an ensemble of state-of-the-art pre-trained deep learning models. The approach leverages transfer learning and ensemble methods to improve the reliability and stability of deepfake detection.

Table of Contents

Overview

Features

Models Used

Dataset

Installation

Usage

Evaluation Metrics

Results

Future Work

References

Overview
With the proliferation of hyper-realistic deepfake content generated by advanced AI, robust detection mechanisms are essential in journalism, cybersecurity, and digital trust. This project evaluates six pre-trained models from Hugging Face for detecting synthetic facial images and explores whether a majority-vote ensemble can enhance detection performance compared to individual models.

Features
Utilizes six pre-trained deep learning models (CNNs, EfficientNet, Vision Transformer).

Employs a simple majority-vote ensemble for final predictions.

Evaluates models on a public Kaggle dataset with balanced real and fake images.

Reports standard classification metrics: accuracy, precision, recall, specificity, sensitivity, and F1 score.

Models Used
The following Hugging Face models are included:

prithivMLmods/Deep-Fake-Detector-Model (ResNet-based)

joyc360/deepfakes (CNN for facial forgery)

dima806/deepfake vs real image detection (Artifact-focused CNN)

DaMsTaR/Detecto-DeepFake Image Detector (EfficientNet variant)

DarkVision/Deepfake detection image (CNN with attention layers)

strangerguardhf/vit deepfake detection (Vision Transformer)

Dataset
Source: Kaggle Real and Fake Face Detection

Composition: 1,000 real and 1,000 fake facial images, resized to 224x224 pixels.

Installation
Clone the repository:

bash
git clone https://github.com/yourusername/deepfake-ensemble-detection.git
cd deepfake-ensemble-detection
Install dependencies:

bash
pip install -r requirements.txt
Usage
Prepare the Dataset:
Download and extract the Kaggle dataset. Place images in the data/ directory, organized into real/ and fake/ folders.

Run Inference:

bash
python detect_deepfakes.py --input_dir data/test/
Ensemble Prediction:
The script automatically aggregates predictions from all six models using majority voting.

Evaluation Metrics
Accuracy: Overall correctness of predictions.

Precision: Proportion of predicted fakes that are actually fake.

Recall (Sensitivity): Proportion of actual fakes correctly identified.

Specificity: Proportion of actual real images correctly identified.

F1 Score: Harmonic mean of precision and recall.

Results
Model	Sensitivity	Specificity	Precision	Recall	F1	Accuracy
M1	0.03	0.98	0.54	0.03	0.04	0.53
M2	1.00	0.00	0.47	1.00	0.64	0.47
M3	0.52	0.46	0.46	0.52	0.49	0.49
M4	0.58	0.40	0.46	0.58	0.51	0.49
M5	0.58	0.40	0.46	0.58	0.51	0.49
M6	0.89	0.11	0.47	0.89	0.62	0.48
Ensemble	0.57	0.41	0.46	0.57	0.51	0.49
The ensemble method produced more balanced and stable results than most individual models.

Future Work
Expand training data to include more diverse manipulation techniques.

Extend detection to video-based deepfakes by analyzing temporal inconsistencies.

Explore multimodal learning by integrating audio and visual features.

Optimize for real-time deployment in practical environments.

References
Goodfellow, I. et al., “Generative Adversarial Networks,” NeurIPS, 2014.

Dosovitskiy, A. et al., “An Image is Worth 16x16 Words,” ICLR, 2021.

Tan, M. and Le, Q., “EfficientNet: Rethinking Model Scaling,” ICML, 2019.

Hugging Face Models: https://huggingface.co/models

Kaggle Dataset: https://www.kaggle.com/datasets/ciplab/real-and-fake-face-detection

For questions or contributions, please open an issue or submit a pull request.
